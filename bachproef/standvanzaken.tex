\chapter{\IfLanguageName{dutch}{Stand van zaken}{State of the art}}
\label{ch:stand-van-zaken}

% Tip: Begin elk hoofdstuk met een paragraaf inleiding die beschrijft hoe
% dit hoofdstuk past binnen het geheel van de bachelorproef. Geef in het
% bijzonder aan wat de link is met het vorige en volgende hoofdstuk.
% Pas na deze inleidende paragraaf komt de eerste sectiehoofding.

%%Dit hoofdstuk bevat je literatuurstudie. De inhoud gaat verder op de inleiding, maar zal het onderwerp van de bachelorproef *diepgaand* uitspitten. De bedoeling is dat de lezer na lezing van dit hoofdstuk helemaal op de hoogte is van de huidige stand van zaken (state-of-the-art) in het onderzoeksdomein. Iemand die niet vertrouwd is met het onderwerp, weet nu voldoende om de rest van het verhaal te kunnen volgen, zonder dat die er nog andere informatie moet over opzoeken \autocite{Pollefliet2011}.

%%Je verwijst bij elke bewering die je doet, vakterm die je introduceert, enz. naar je bronnen. In \LaTeX{} kan dat met het commando \texttt{$\backslash${textcite\{\}}} of \texttt{$\backslash${autocite\{\}}}. Als argument van het commando geef je de ``sleutel'' van een ``record'' in een bibliografische databank in het Bib\LaTeX{}-formaat (een tekstbestand). Als je expliciet naar de auteur verwijst in de zin, gebruik je \texttt{$\backslash${}textcite\{\}}.
%%Soms wil je de auteur niet expliciet vernoemen, dan gebruik je \texttt{$\backslash${}autocite\{\}}. In de volgende paragraaf een voorbeeld van elk.

%%\textcite{Knuth1998} schreef een van de standaardwerken over sorteer- en zoekalgoritmen. Experten zijn het erover eens dat cloud computing een interessante opportuniteit vormen, zowel voor gebruikers als voor dienstverleners op vlak van informatietechnologie~\autocite{Creeger2009}.

%%\lipsum[7-20]

In dit hoofdstuk gaan we dieper ingaan op het onderwerp van deze bachelorproef. In de inleiding hebben we reeds de titel uiteengehaald om een beter begrip te krijgen van de basis van het onderwerp. Dit onderdeel zal beginnen met een sectie over de verschillende logparsers die zullen gehanteerd worden binnen het onderzoek. Dit zullen er in totaal 16 zijn. Hiervan zijn er 13 die reeds vernoemd worden in de paper `Tools and Benchmarks for Automated Log Parsing` \autocite{TBA2019}. In de tweede sectie gaan we dieper in op de verschillende systeem logs die binnen het onderzoek aan bod zullen komen. Dit zijn er x, waarvan y reeds vernoemd worden in de paper `Tools and Benchmarks for Automated Log Parsing` \autocite{TBA2019}. Na deze secties zal men reeds een goed begrip hebben van de verschillende parsers die onderzocht worden. In de derde en laatste sectie gaan we dan ook dieper in op de gebruikte technologieën voor deze bachelorproef om een goed overzicht te vormen van alle diepere kennis vereist om de rest van het onderzoek te kunnen volgen.

\section{Parsers - 16}
In deze sectie zullen we alle parsers die worden benuttigd binnen deze bachelproef oplijsten met een diepgaande uitleg over de werking van elke parser. Deze sectie zal beginnen met de 13 parsers vanuit de paper `Tools and Benchmarks for Automated Log Parsing` \autocite{TBA2019} en als laatste de 3 extra parsers opgenomen binnen dit onderzoek.

\subsection{AEL -  Abstracting Execution Logs}
De informatie binnen deze subsectie over AEL (Abstracting Execution Logs) is gebaseerd op twee papers namelijk, de paper `An automated approach for abstracting execution logs to execution events` \autocite{jiang2008automated} en de paper `Abstracting Execution Logs to Execution Events for Enterprise Applications` \autocite{jiang2008abstracting}. 

Zoals reeds vermeld staat AEL voor Abstracting Execution Logs. Deze naam geeft niet echt meer inzicht in de samenstelling van AEL. AEL is opgesteld op basis van Execution Logs, i.e. logs die lijnen tekst bevatten (log lines) gegenereerd bij een output van een applicatie. Deze logs geven een beter begrip van de applicatie en zijn zeer behulpzaam bij het zoeken en oplossen van problemen binnen de applicatie. Echter hebben deze soort logs geen vaste structuur en verschillen ze teveel van applicatie tot applicatie. AEL is ontworpen om automatische analyse van deze soort logs mogelijk te maken door ze een vaste structuur te geven. AEL gebruikt abstractie van de logs om een structuur te vinden in elke lijn en dan deze structuur vast te leggen over de volledige file zodat automatische analyse niet meer onmogelijk is. De manier waarop dit mogelijk is, is door elke logline te gaan mappen naar hun respectievelijke execution event. Dit is mogelijk omdat alle log files bestaan uit beide statische en dynamische informatie, dit is dan ook de enige overeenkomstige structuur. Op basis van de statische informatie kan men het execution event afleiden. De dynamische informatie heeft dan weer betrekking op de momentopname van het event (Dit zorgt voor de verschillen binnen de lijnen). AEL gebruikt clone detection om gelijkaardige woorden (tokens) in de lijnen te vinden om ze te groeperen, zoals bijvoorbeeld: fail en failure. Door de clone detectie kan AEL op basis van deze groeperingen een parameter meegeven aan deze lijnen om zo een duidelijk overzicht te houden. Wat AEL dus doet is van verschillende lijnen in een logfile een gelijke structuur opbouwen zodat deze geanalyseerd kunnen worden. De verschillende stappen die hierin worden doorlopen zijn:

\begin{itemize}
    \item De anonymiseringsstap: Deze stap maakt gebruik van heuristieken om de structuur de verduidelijken. Zo worden eerst de dynamische delen van een lijn gezocht, i.e. de delen die verschillend zijn van lijn tot lijn door de meegegeven informatie en parameters. Hierbij worden alle parameters vervangen met `v`. Er wordt hierna gezocht naar woorden die functies kunnen aangeven zoals `is` dat wordt vervangen door `=`. Zo wordt de lijn `Total shopping cost is 250` vervangen door `Total shopping cost = v`.
    \item De tokeniseringsstap: Deze stap gaat de geanonymiseerde lijnen indelen in verschillende groepen (bins) aan de hand  van het aantal woorden en parameters in de lijnen. Dit stelt ons in staat om in een beperkte tijd een groot aantal lijnen te verwerken. Omdat de analyse in de volgende stap verloopt per bin in plaats van per logfile. Het aantal parameters wordt geschat door het optellen van het voorkomen van `\$v`. Loglines met een gelijke lengte en aantal parameters worden samengebracht in dezelfde bin.
    \item De categoriseringsstap: Dit is de stap waarbij de structuur bepaald wordt. Hierbij gaat over elke bin geïtereerd worden en de lijnen binnen deze bin zullen geabstraheerd worden naar bepaalde execution events. De execution events die mogelijk zijn worden bijgehouden in een database voor de toekomstige referenties. Hoe dit tewerk gaat is door te beginnen met het overlopen van de eerste bin en voor de eerste lijn zal er nog geen execution event zijn dus deze zal worden opgeslaan als execution event volgens zijn patroon, i.e. 3-0, omdat deze lijn 3 woorden bevat en 0 parameters. Hierna zal de tweede lijn binnen de eerste bin overlopen worden en zal eerst gecheckt worden of deze tot het 3-0 event behoort of niet.
    \item De reconcile stap: Hierbij worden de execution events overlopen om te checken of er niets zou misgelopen zijn bij de anonymiseringsstap. Bij de eerste stap kan de heuristiek, door de opbouw van de lijnen, eventueel parameters over het hoofd zien. Dan zullen deze lijnen met hun respectievelijke parameters waarschijnlijk gemapt worden op verschillende execution events, ookal zijn dit eigenlijk lijnen die tot hetzelfde execution event behoren. Om zo'n fouten te spotten binnen de execution events in de database moeten de lijnen binnen de events aan bepaalde eigenschappen voldoen, namelijk:\\
    1. Ze moeten tot dezelfde bin behoren. \\
    2. Ze verschillen van elkaar met 1 woord op dezelfde plaats. \\
    3. Er is een beperkt aantal van deze execution events, bijvoorbeeld: Er zijn 5 events die op elkaar gelijken. \\
\end{itemize}

\subsection{Drain}
De informatie binnen deze subsectie over Drain is gebaseerd op de paper `Drain: An Online Log Parsing Approach with Fixed Depth Tree` \autocite{he2017drain}.

Drain is de parser die binnen de paper waarop deze bachelorproef dieper ingaat \autocite{TBA2019} naarboven kwam als de meest efficiënte parser. We gaan dan ook een goede kennis moeten hebben over de werking van deze parser. Drain is gebaseerd op het online parsen logs, dit omdat het parsen van logs met een offline methode moet wachten tot na het collecteren van de logs en door de exponentiële stijging van het aantal logs worden deze methodes zeer tijdinefficiënt. Drain gaat logs parsen in een soort van stream dit om het volledige parsing process te versnellen.


\section{Systeem logs - 5}
\section{Technologie}
